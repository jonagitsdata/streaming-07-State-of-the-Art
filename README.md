# streaming-07-State-of-the-Art
## Author: Jonathan Nkangabwa
## Date: 02/22/23
Final project where I build a unique custom streaming process based on working with Python, pika, and RabbitMQ.
## Module 7: Project (Option 1)
This is the first of two options for Module 7.

You'll create a project that builds on your prior work in the course. 
You'll apply what you've learned to new data.
Submit Early
No late submissions accepted.

Note:

This policy is regardless of the validity of any last minute issues.
To reduce risk, complete and submit your final project early - before the deadline.
Requirements - Custom Streaming Project
Be sure to address these in your project:

Create a custom GitHub project repo to showcase your skills.
Describe and plan an new implementation using RabbitMQ for streaming data. 
Create one or more custom producers.
Create one or more custom consumers.
You can simulate your initial data source using Faker or some other file - or read from an API (not too much, too often, or too fast!)
How did you explore exchanges and queues?
Did you use time windows?
What made this an interesting streaming project for you?
Data Sources
You can choose your data source from any option:

CSV file, text file, SQLite database, etc.
Web API requesting live data
Faker for all of the information.
Q: can we fake our entire data set or do need to find one from online? 

A: You can fake it all.

Using faker or your own faking function, whatever you like. That’s likely the safest and most reliable.

But also, faking might make perfectly clean data, so it might not show all your skills. After everything works well with fake good data, you might introduce some “bad data” issues – missing values, invalid items, unexpected characters, etc. and handle them (but only after the good data is working). Start easy. 

 

README.md
Your README.md must:

Be professionally formatted.
Include a title for your project and have a well-named repo. (No spaces!)
Describe your unique steaming analytics project - what / why 
Describe and link to your data original data sources. 
Describe your process - producers, consumers, exchanges, queues
Document the output of your simulation or process.
Readers shouldn’t have to download and execute any Python code to verify your results. 
If scripts, put the console output into out.txt files
If notebooks, execute the notebook first - before committing & pushing to GitHub - so the results appear.
If showing concurrent messages, use multiple terminals and show using screen shots.
Displaying screenshots of RabbitMQ queues, etc. can also make it clear what your project is doing. 
Submit
Include the prompts below in your submission, along with your answers.

Submit a clickable link to your GitHub repo. 
How did you choose your project?
How did it go? 
What was the hardest part?
What was most interesting?
What are you most proud of?
 
